{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab1eebf",
   "metadata": {},
   "source": [
    "# Imports & Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d35dd0",
   "metadata": {},
   "source": [
    "We will import the necessary packages utilized for modeling/evaluation in this notebook. We also make sure that our viualizations are exported to results/figures/modeling & evalutation/ directory, and metrics are exported to results/metrics directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation complete\n",
      "Compilation complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Allow imports from ../src directory\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.train_models import (\n",
    "    build_logistic_regression_model,\n",
    "    build_random_forest_model,\n",
    "    build_xgboost\n",
    ")\n",
    "from src.preprocessing import (\n",
    "    train_val_test_split\n",
    ")\n",
    "FIG_DIR = \"../results/figures/modeling & evaluation/\"\n",
    "METRICS_DIR = \"../results/metrics/\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "_plt_original_show = plt.show\n",
    "_plt_fig_counter = {\"count\": 0}\n",
    "def _save_and_show(*args, **kwargs) -> None:\n",
    "    _plt_fig_counter[\"count\"] += 1\n",
    "    filename = os.path.join(FIG_DIR, f\"figure_{_plt_fig_counter['count']:03d}.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "    _plt_original_show(*args, **kwargs)\n",
    "plt.show = _save_and_show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34053443",
   "metadata": {},
   "source": [
    "- `pandas`: data wrangling and CSV loading\n",
    "- `numpy`: array and numerical operations\n",
    "- `matplotlib` & `seaborn`: visualizations and plots\n",
    "- `os`, `sys`, `pathlib`: directory management and custom imports\n",
    "- `sklearn`: train/test splitting and evaluation metrics. \n",
    "-  `src.train_models`: Logistic Regression, Random Forest and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76189d3a",
   "metadata": {},
   "source": [
    "# Feature and Target Seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882e536",
   "metadata": {},
   "source": [
    "Load `ais_data_model_ready` and seperate features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97422bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 7\n",
      "Number of samples: 326066\n",
      "List of features names: ['sog', 'cog', 'heading', 'width', 'length', 'draught', 'shiptype']\n",
      "Target variable: navigationalstatus\n"
     ]
    }
   ],
   "source": [
    "model_df = pd.read_csv(\"../data/ais_data_model_ready.csv\")\n",
    "TARGET_COL = \"navigationalstatus\"\n",
    "X = model_df.drop(columns=[TARGET_COL])\n",
    "y = model_df[TARGET_COL]\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"List of features names: {X.columns.tolist()}\")\n",
    "print(f\"Target variable: {y.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269aeb82",
   "metadata": {},
   "source": [
    "# Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2c3c9",
   "metadata": {},
   "source": [
    "Two-stage stratified split to preserve class distribution across all splits:\n",
    "\n",
    "1. Stage 1 (80/20): 80% -> Train+Val, 20% -> Test\n",
    "2. Stage 2 (80/20 of the 80%): 80% of 80% -> Train (64%), 20% of 80% -> Val (16%)\n",
    "\n",
    "Final Distribution\n",
    "- Training: 64%, Validation: 16%, Test: 20%\n",
    "\n",
    "Function Parameters\n",
    "- `test_size`: 20% reserved for final evaluation (untouched during development)\n",
    "- `val_size`: 16% for hyperparameter tuning\n",
    "- `random_state`: Ensures reproducibility\n",
    "- Stratified: Preserves imbalanced class distribution across all splits\n",
    "\n",
    "The function returns 6 variables: `X_train, X_val, X_test, y_train, y_val, y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c65658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val/test split complete!\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,  # 20% reserved for final evaluation (untouched during development)\n",
    "    val_size=0.16,  # 16% for hyperparameter tuning\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train/val/test split complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3190c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 326066\n",
      "\n",
      "Train set:\n",
      "  Shape: (208682, 7)\n",
      "  Percentage: 64.0%\n",
      "\n",
      "Validation set:\n",
      "  Shape: (52170, 7)\n",
      "  Percentage: 16.0%\n",
      "\n",
      "Test set:\n",
      "  Shape: (65214, 7)\n",
      "  Percentage: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Print split information\n",
    "print(f\"\\nTotal samples: {len(X)}\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Shape: {X_train.shape}\")\n",
    "print(f\"  Percentage: {len(X_train)/len(X)*100:.1f}%\")\n",
    "print(f\"\\nValidation set:\")\n",
    "print(f\"  Shape: {X_val.shape}\")\n",
    "print(f\"  Percentage: {len(X_val)/len(X)*100:.1f}%\")\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Shape: {X_test.shape}\")\n",
    "print(f\"  Percentage: {len(X_test)/len(X)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d515fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set class distribution:\n",
      "navigationalstatus\n",
      "At anchor                                                0.001509\n",
      "Constrained by her draught                               0.037617\n",
      "Engaged in fishing                                       0.015061\n",
      "Moored                                                   0.010336\n",
      "Power-driven vessel pushing ahead or towing alongside    0.000724\n",
      "Power-driven vessel towing astern                        0.000757\n",
      "Reserved for future amendment [HSC]                      0.005362\n",
      "Restricted maneuverability                               0.004974\n",
      "Under way sailing                                        0.004049\n",
      "Under way using engine                                   0.917779\n",
      "Unknown value                                            0.001831\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check set class distribution\n",
    "print(\"\\nTrain set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fc0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set class distribution:\n",
      "navigationalstatus\n",
      "At anchor                                                0.001514\n",
      "Constrained by her draught                               0.037627\n",
      "Engaged in fishing                                       0.015066\n",
      "Moored                                                   0.010332\n",
      "Power-driven vessel pushing ahead or towing alongside    0.000728\n",
      "Power-driven vessel towing astern                        0.000748\n",
      "Reserved for future amendment [HSC]                      0.005348\n",
      "Restricted maneuverability                               0.004965\n",
      "Under way sailing                                        0.004064\n",
      "Under way using engine                                   0.917788\n",
      "Unknown value                                            0.001821\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check validation set class distribution\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "print(y_val.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b64593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set class distribution:\n",
      "navigationalstatus\n",
      "At anchor                                                0.001503\n",
      "Constrained by her draught                               0.037615\n",
      "Engaged in fishing                                       0.015058\n",
      "Moored                                                   0.010351\n",
      "Power-driven vessel pushing ahead or towing alongside    0.000721\n",
      "Power-driven vessel towing astern                        0.000751\n",
      "Reserved for future amendment [HSC]                      0.005367\n",
      "Restricted maneuverability                               0.004984\n",
      "Under way sailing                                        0.004048\n",
      "Under way using engine                                   0.917778\n",
      "Unknown value                                            0.001825\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check test set class distribution\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b45d7",
   "metadata": {},
   "source": [
    "# Define Evaluation Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c2432",
   "metadata": {},
   "source": [
    "Create a function that will provide us a standard to score each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa15228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function instantiated.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_classifier(model, X, y, model_name, split_name):\n",
    "    \"\"\"\n",
    "    Evaluate a fitted classifier and return a dictionary of metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: A fitted sklearn-style classifier with .predict() method\n",
    "        X: Feature matrix (NumPy array or pandas DataFrame)\n",
    "        y: True labels\n",
    "        model_name: String identifier for the model (e.g., \"Logistic Regression\")\n",
    "        split_name: String identifier for the data split (e.g., \"val\" or \"test\")\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all computed metrics, predictions, and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    macro_f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "    weighted_f1 = f1_score(y, y_pred, average=\"weighted\")\n",
    "    precision_macro = precision_score(y, y_pred, average=\"macro\")\n",
    "    recall_macro = recall_score(y, y_pred, average=\"macro\")\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cr = classification_report(y, y_pred)\n",
    "    \n",
    "    # Print concise summary\n",
    "    print(\n",
    "        f\"{model_name} [{split_name}] | \"\n",
    "        f\"Accuracy: {accuracy:.3f} | \"\n",
    "        f\"Macro-F1: {macro_f1:.3f} | \"\n",
    "        f\"Weighted-F1: {weighted_f1:.3f} | \"\n",
    "        f\"Precision (Macro): {precision_macro:.3f} | \"\n",
    "        f\"Recall (Macro): {recall_macro:.3f}\"\n",
    "    )\n",
    "    \n",
    "    # Return results dictionary\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"split\": split_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": cr,\n",
    "        \"y_true\": y,\n",
    "        \"y_pred\": y_pred\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function instantiated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15614b5b",
   "metadata": {},
   "source": [
    "# Build and Train Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maritime-ais-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
