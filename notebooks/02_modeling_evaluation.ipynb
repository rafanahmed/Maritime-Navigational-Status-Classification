{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab1eebf",
   "metadata": {},
   "source": [
    "# Imports & Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d35dd0",
   "metadata": {},
   "source": [
    "We will import the necessary packages utilized for modeling/evaluation in this notebook. We also make sure that our viualizations are exported to results/figures/modeling & evalutation/ directory, and metrics are exported to results/metrics directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e9f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation complete\n",
      "Compilation complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Allow imports from ../src directory\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.train_models import (\n",
    "    build_logistic_regression_model,\n",
    "    build_random_forest_model,\n",
    "    build_xgboost\n",
    ")\n",
    "from src.preprocessing import (\n",
    "    train_val_test_split,\n",
    "    build_preprocessor\n",
    ")\n",
    "FIG_DIR = \"../results/figures/modeling & evaluation/\"\n",
    "METRICS_DIR = \"../results/metrics/\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "_plt_original_show = plt.show\n",
    "_plt_fig_counter = {\"count\": 0}\n",
    "def _save_and_show(*args, **kwargs) -> None:\n",
    "    _plt_fig_counter[\"count\"] += 1\n",
    "    filename = os.path.join(FIG_DIR, f\"figure_{_plt_fig_counter['count']:03d}.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "    _plt_original_show(*args, **kwargs)\n",
    "plt.show = _save_and_show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34053443",
   "metadata": {},
   "source": [
    "- `pandas`: data wrangling and CSV loading\n",
    "- `numpy`: array and numerical operations\n",
    "- `matplotlib` & `seaborn`: visualizations and plots\n",
    "- `os`, `sys`, `pathlib`: directory management and custom imports\n",
    "- `sklearn`: train/test splitting, evaluation metrics and label encoding. \n",
    "-  `src.preprocessing`: utilities for feature/target separation, stratified splitting, and building preprocessing pipelines.\n",
    "-  `src.train_models`: Logistic Regression, Random Forest and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76189d3a",
   "metadata": {},
   "source": [
    "# Feature and Target Seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882e536",
   "metadata": {},
   "source": [
    "Load `ais_data_model_ready` and seperate features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97422bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 7\n",
      "Number of samples: 326066\n",
      "List of features names: ['sog', 'cog', 'heading', 'width', 'length', 'draught', 'shiptype']\n",
      "Target variable: navigationalstatus\n"
     ]
    }
   ],
   "source": [
    "model_df = pd.read_csv(\"../data/ais_data_model_ready.csv\")\n",
    "TARGET_COL = \"navigationalstatus\"\n",
    "X = model_df.drop(columns=[TARGET_COL])\n",
    "y = model_df[TARGET_COL]\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"List of features names: {X.columns.tolist()}\")\n",
    "print(f\"Target variable: {y.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269aeb82",
   "metadata": {},
   "source": [
    "# Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2c3c9",
   "metadata": {},
   "source": [
    "Two-stage stratified split to preserve class distribution across all splits:\n",
    "\n",
    "1. Stage 1 (80/20): 80% -> Train+Val, 20% -> Test\n",
    "2. Stage 2 (80/20 of the 80%): 80% of 80% -> Train (64%), 20% of 80% -> Val (16%)\n",
    "\n",
    "Final Distribution\n",
    "- Training: 64%, Validation: 16%, Test: 20%\n",
    "\n",
    "Function Parameters\n",
    "- `test_size`: 20% reserved for final evaluation (untouched during development)\n",
    "- `val_size`: 16% for hyperparameter tuning\n",
    "- `random_state`: Ensures reproducibility\n",
    "- Stratified: Preserves imbalanced class distribution across all splits\n",
    "\n",
    "The function returns 6 variables: `X_train, X_val, X_test, y_train, y_val, y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c65658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val/test split complete!\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,  # 20% reserved for final evaluation (untouched during development)\n",
    "    val_size=0.16,  # 16% for hyperparameter tuning\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train/val/test split complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3190c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 326066\n",
      "\n",
      "Train set:\n",
      "  Shape: (208682, 7)\n",
      "  Percentage: 64.0%\n",
      "\n",
      "Validation set:\n",
      "  Shape: (52170, 7)\n",
      "  Percentage: 16.0%\n",
      "\n",
      "Test set:\n",
      "  Shape: (65214, 7)\n",
      "  Percentage: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Print split information\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Shape: {X_train.shape}\")\n",
    "print(f\"  Percentage: {len(X_train)/len(X)*100:.1f}%\")\n",
    "print(f\"\\nValidation set:\")\n",
    "print(f\"  Shape: {X_val.shape}\")\n",
    "print(f\"  Percentage: {len(X_val)/len(X)*100:.1f}%\")\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Shape: {X_test.shape}\")\n",
    "print(f\"  Percentage: {len(X_test)/len(X)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d515fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class distribution:\n",
      "navigationalstatus\n",
      "At anchor                                                0.001509\n",
      "Constrained by her draught                               0.037617\n",
      "Engaged in fishing                                       0.015061\n",
      "Moored                                                   0.010336\n",
      "Power-driven vessel pushing ahead or towing alongside    0.000724\n",
      "Power-driven vessel towing astern                        0.000757\n",
      "Reserved for future amendment [HSC]                      0.005362\n",
      "Restricted maneuverability                               0.004974\n",
      "Under way sailing                                        0.004049\n",
      "Under way using engine                                   0.917779\n",
      "Unknown value                                            0.001831\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check set class distribution\n",
    "print(\"Train set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fc0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set class distribution:\n",
      "navigationalstatus\n",
      "At anchor                                                0.001514\n",
      "Constrained by her draught                               0.037627\n",
      "Engaged in fishing                                       0.015066\n",
      "Moored                                                   0.010332\n",
      "Power-driven vessel pushing ahead or towing alongside    0.000728\n",
      "Power-driven vessel towing astern                        0.000748\n",
      "Reserved for future amendment [HSC]                      0.005348\n",
      "Restricted maneuverability                               0.004965\n",
      "Under way sailing                                        0.004064\n",
      "Under way using engine                                   0.917788\n",
      "Unknown value                                            0.001821\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check validation set class distribution\n",
    "print(\"Validation set class distribution:\")\n",
    "print(y_val.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b64593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set class distribution:\n",
      "navigationalstatus\n",
      "At anchor                                                0.001503\n",
      "Constrained by her draught                               0.037615\n",
      "Engaged in fishing                                       0.015058\n",
      "Moored                                                   0.010351\n",
      "Power-driven vessel pushing ahead or towing alongside    0.000721\n",
      "Power-driven vessel towing astern                        0.000751\n",
      "Reserved for future amendment [HSC]                      0.005367\n",
      "Restricted maneuverability                               0.004984\n",
      "Under way sailing                                        0.004048\n",
      "Under way using engine                                   0.917778\n",
      "Unknown value                                            0.001825\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check test set class distribution\n",
    "print(\"Test set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b45d7",
   "metadata": {},
   "source": [
    "# Define Evaluation Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c2432",
   "metadata": {},
   "source": [
    "Create a function that will provide us a standard to score each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa15228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function instantiated.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_classifier(model, X, y, model_name, split_name, label_encoder=None):\n",
    "    \"\"\"\n",
    "    Evaluate a fitted classifier and return a dictionary of metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: A fitted sklearn-style classifier with .predict() method\n",
    "        X: Feature matrix (NumPy array or pandas DataFrame)\n",
    "        y: True labels\n",
    "        model_name: String identifier for the model (e.g., \"Logistic Regression\")\n",
    "        split_name: String identifier for the data split (e.g., \"val\" or \"test\")\n",
    "        label_encoder: Optional LabelEncoder to decode predictions (required for XGBoost)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all computed metrics, predictions, and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Decode predictions if label_encoder provided (for XGBoost)\n",
    "    if label_encoder is not None:\n",
    "        y_pred = label_encoder.inverse_transform(y_pred)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    macro_f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "    weighted_f1 = f1_score(y, y_pred, average=\"weighted\")\n",
    "    precision_macro = precision_score(y, y_pred, average=\"macro\")\n",
    "    recall_macro = recall_score(y, y_pred, average=\"macro\")\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cr = classification_report(y, y_pred)\n",
    "    \n",
    "    # Print concise summary\n",
    "    print(\n",
    "        f\"{model_name} [{split_name}] | \"\n",
    "        f\"Accuracy: {accuracy:.3f} | \"\n",
    "        f\"Macro-F1: {macro_f1:.3f} | \"\n",
    "        f\"Weighted-F1: {weighted_f1:.3f} | \"\n",
    "        f\"Precision (Macro): {precision_macro:.3f} | \"\n",
    "        f\"Recall (Macro): {recall_macro:.3f}\"\n",
    "    )\n",
    "    \n",
    "    # Return results dictionary\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"split\": split_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": cr,\n",
    "        \"y_true\": y,\n",
    "        \"y_pred\": y_pred\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function instantiated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15614b5b",
   "metadata": {},
   "source": [
    "# Build and Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f20ae",
   "metadata": {},
   "source": [
    "From `train_models.py`, we are going to use 3 models:\n",
    "- Logistic Regression:\n",
    "    - Used as a simple linear baseline that is interpretable and effective for many classification problems.\n",
    "- Random Forest:\n",
    "    - Chosen as a robust nonlinear baseline capable of capturing complex patterns and interactions in the data.\n",
    "- XGBoost:\n",
    "    - Included as a strong performance baseline due to its efficiency and state-of-the-art results in many classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf592bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting preprocessor on training data...\n",
      "Training data shape after preprocessing: (208682, 23)\n",
      "Validation data shape after preprocessing: (52170, 23)\n",
      "Test data shape after preprocessing: (65214, 23)\n",
      "Preprocessing complete.\n",
      "\n",
      "Building models...\n",
      "The models are built.\n",
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/maritime-ais-ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training complete.\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest training complete.\n",
      "\n",
      "Prepping target labels for XGBoost...\n",
      "Target labels encoded.\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost training complete.\n",
      "\n",
      "\n",
      "Model training complete. Awaiting comparison on validation set.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate preprocessor\n",
    "preprocessor = build_preprocessor()\n",
    "\n",
    "# Fit preprocessor on training data. Transform splits.\n",
    "print(\"Fitting preprocessor on training data...\")\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "print(f\"Training data shape after preprocessing: {X_train_preprocessed.shape}\")\n",
    "print(f\"Validation data shape after preprocessing: {X_val_preprocessed.shape}\")\n",
    "print(f\"Test data shape after preprocessing: {X_test_preprocessed.shape}\")\n",
    "print(\"Preprocessing complete.\\n\")\n",
    "\n",
    "# Build Models\n",
    "print(\"Building models...\")\n",
    "logistic_regression_model = build_logistic_regression_model()\n",
    "random_forest_model = build_random_forest_model()\n",
    "xgboost_model = build_xgboost()\n",
    "print(\"The models are built.\\n\")\n",
    "\n",
    "# Train Models\n",
    "print(\"Training Logistic Regression...\")\n",
    "logistic_regression_model.fit(X_train_preprocessed, y_train)\n",
    "print(\"Logistic Regression training complete.\\n\")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "random_forest_model.fit(X_train_preprocessed, y_train)\n",
    "print(\"Random Forest training complete.\\n\")\n",
    "\n",
    "# Encode target labels\n",
    "print(\"Prepping target labels for XGBoost...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "print(\"Target labels encoded.\\n\")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgboost_model.fit(X_train_preprocessed, y_train_encoded)\n",
    "print(\"XGBoost training complete.\\n\")\n",
    "print(\"\\nModel training complete. Awaiting comparison on validation set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e080da",
   "metadata": {},
   "source": [
    "# Compare Models on Validation Set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maritime-ais-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
